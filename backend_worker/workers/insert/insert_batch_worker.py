"""Worker d'insertion - Insertion des donn√©es group√©es en base de donn√©es

Responsabilit√©s :
- Insertion via l'API HTTP uniquement (pas d'acc√®s direct DB)
- Utilisation de l'entity_manager pour r√©solution automatique des r√©f√©rences
- Insertion par batch optimis√©e pour Raspberry Pi
- Publication de la progression

Architecture :
1. discovery ‚Üí 2. extract_metadata ‚Üí 3. process_entities ‚Üí 4. insert_batch
"""

import os
import httpx
import time
import asyncio
from typing import Dict, Any, List

from backend_worker.utils.logging import logger
from backend_worker.utils.pubsub import publish_event
from backend_worker.celery_app import celery
from backend_worker.services.entity_manager import (
    create_or_get_artists_batch,
    create_or_get_albums_batch,
    create_or_update_tracks_batch,
    create_or_get_genre,
    create_or_get_genre_tag,
    create_or_get_mood_tag,
    on_artists_inserted_callback,
    on_albums_inserted_callback,
    on_tracks_inserted_callback,
    execute_graphql_query
)
from backend_worker.services.deferred_queue_service import deferred_queue_service


@celery.task(name="insert.direct_batch", queue="insert", bind=True)
def insert_batch_direct(self, insertion_data: Dict[str, Any]):
    """Ins√®re en base de donn√©es via l'API HTTP uniquement.

    Utilise l'entity_manager pour la r√©solution automatique des r√©f√©rences.
    Optimis√©e pour Raspberry Pi : batches plus petits, timeouts r√©duits.

    Args:
        insertion_data: Donn√©es group√©es pr√™tes pour insertion

    Returns:
        R√©sultat de l'insertion
    """
    # Ex√©cuter la logique asynchrone dans un event loop synchrone
    return asyncio.run(_insert_batch_direct_async(self, insertion_data))


async def enqueue_enrichment_tasks_for_artists(client: httpx.AsyncClient, artist_ids: List[int], library_api_url: str) -> None:
    """
    Enqueue des t√¢ches d'enrichissement pour les artistes qui n'ont pas de covers.

    Args:
        client: Client HTTP asynchrone
        artist_ids: Liste des IDs d'artistes ins√©r√©s
        library_api_url: URL de l'API library
    """
    try:
        if not artist_ids:
            logger.debug("[ENRICHMENT] Aucun artiste √† traiter")
            return

        logger.info(f"[ENRICHMENT] V√©rification covers pour {len(artist_ids)} artistes: {artist_ids}")

        enqueued_count = 0

        for artist_id in artist_ids:
            try:
                logger.debug(f"[ENRICHMENT] V√©rification cover pour artiste {artist_id}")
                # V√©rifier si l'artiste a d√©j√† une cover
                # L'endpoint /api/covers/artist/{id} retourne des donn√©es binaires (image), pas du JSON
                response = await client.get(f"{library_api_url}/api/covers/artist/{artist_id}")
                logger.debug(f"[ENRICHMENT] R√©ponse API covers pour artiste {artist_id}: {response.status_code}")

                # Si status 200, l'image existe (donn√©es binaires), donc on skip l'enrichissement
                if response.status_code == 200:
                    logger.debug(f"[ENRICHMENT] Artiste {artist_id} a d√©j√† une cover (image trouv√©e), skip")
                    continue

                logger.info(f"[ENRICHMENT] Artiste {artist_id} n'a pas de cover, enqueue t√¢che")

                # Enqueue t√¢che d'enrichissement artiste
                task_data = {
                    "type": "artist",
                    "id": artist_id
                }

                # DIAGNOSTIC: Logs d√©taill√©s pour identifier la cause de l'√©chec
                logger.info(f"[ENRICHMENT DIAGNOSTIC] Tentative enqueue artiste {artist_id} avec donn√©es: {task_data}")
                logger.info(f"[ENRICHMENT DIAGNOSTIC] Redis disponible: {deferred_queue_service.redis is not None}")
                
                if deferred_queue_service.redis:
                    try:
                        # Test de ping Redis
                        deferred_queue_service.redis.ping()
                        logger.info(f"[ENRICHMENT DIAGNOSTIC] Redis ping r√©ussi pour artiste {artist_id}")
                    except Exception as ping_error:
                        logger.error(f"[ENRICHMENT DIAGNOSTIC] Redis ping √©chou√© pour artiste {artist_id}: {ping_error}")
                
                success = deferred_queue_service.enqueue_task(
                    "deferred_enrichment",
                    task_data,
                    priority="normal",
                    delay_seconds=60  # D√©lai de 1 minute pour √©viter surcharge imm√©diate
                )

                if success:
                    logger.info(f"[ENRICHMENT] ‚úÖ T√¢che enrichissement enqueued pour artiste {artist_id}")
                    enqueued_count += 1
                else:
                    # DIAGNOSTIC: Log d√©taill√© de l'√©chec
                    logger.error(f"[ENRICHMENT] ‚ùå √âchec enqueue t√¢che artiste {artist_id}")
                    logger.error(f"[ENRICHMENT DIAGNOSTIC] Donn√©es qui ont √©chou√©: {task_data}")
                    logger.error(f"[ENRICHMENT DIAGNOSTIC] Taille des donn√©es: {len(str(task_data))} caract√®res")
                    
                    # V√©rifier l'√©tat de Redis apr√®s l'√©chec
                    if deferred_queue_service.redis:
                        try:
                            info = deferred_queue_service.redis.info()
                            logger.error(f"[ENRICHMENT DIAGNOSTIC] Redis info apr√®s √©chec: used_memory={info.get('used_memory', 'N/A')}")
                        except Exception as info_error:
                            logger.error(f"[ENRICHMENT DIAGNOSTIC] Impossible d'obtenir info Redis: {info_error}")
                    else:
                        logger.error(f"[ENRICHMENT DIAGNOSTIC] Redis non disponible lors de l'enqueue")

            except Exception as e:
                logger.error(f"[ENRICHMENT] Erreur v√©rification artiste {artist_id}: {str(e)}")

        logger.info(f"[ENRICHMENT] Total t√¢ches enqueued pour artistes: {enqueued_count}/{len(artist_ids)}")

    except Exception as e:
        logger.error(f"[ENRICHMENT] Erreur g√©n√©rale enqueue artistes: {str(e)}")


async def enqueue_enrichment_tasks_for_albums(client: httpx.AsyncClient, album_ids: List[int], library_api_url: str) -> None:
    """
    Enqueue des t√¢ches d'enrichissement pour les albums qui n'ont pas de covers.

    Args:
        client: Client HTTP asynchrone
        album_ids: Liste des IDs d'albums ins√©r√©s
        library_api_url: URL de l'API library
    """
    try:
        if not album_ids:
            logger.debug("[ENRICHMENT] Aucun album √† traiter")
            return

        logger.info(f"[ENRICHMENT] V√©rification covers pour {len(album_ids)} albums: {album_ids}")

        enqueued_count = 0

        for album_id in album_ids:
            try:
                logger.debug(f"[ENRICHMENT] V√©rification cover pour album {album_id}")
                # V√©rifier si l'album a d√©j√† une cover
                # L'endpoint /api/covers/album/{id} retourne des donn√©es binaires (image), pas du JSON
                response = await client.get(f"{library_api_url}/api/covers/album/{album_id}")
                logger.debug(f"[ENRICHMENT] R√©ponse API covers pour album {album_id}: {response.status_code}")

                # Si status 200, l'image existe (donn√©es binaires), donc on skip l'enrichissement
                if response.status_code == 200:
                    logger.debug(f"[ENRICHMENT] Album {album_id} a d√©j√† une cover (image trouv√©e), skip")
                    continue

                # R√©cup√©rer les infos de l'album pour avoir le MBID
                album_response = await client.get(f"{library_api_url}/api/albums/{album_id}")
                logger.debug(f"[ENRICHMENT] R√©ponse API album pour album {album_id}: {album_response.status_code}")

                if album_response.status_code != 200:
                    logger.warning(f"[ENRICHMENT] Impossible de r√©cup√©rer album {album_id}")
                    continue

                album_data = album_response.json()
                mb_release_id = album_data.get("musicbrainz_albumid")
                logger.debug(f"[ENRICHMENT] Album {album_id} MBID: {mb_release_id}")

                logger.info(f"[ENRICHMENT] Album {album_id} n'a pas de cover, enqueue t√¢che")

                # Enqueue t√¢che d'enrichissement album
                task_data = {
                    "type": "album",
                    "id": album_id,
                    "mb_release_id": mb_release_id
                }

                # DIAGNOSTIC: Logs d√©taill√©s pour identifier la cause de l'√©chec
                logger.info(f"[ENRICHMENT DIAGNOSTIC] Tentative enqueue album {album_id} avec donn√©es: {task_data}")
                logger.info(f"[ENRICHMENT DIAGNOSTIC] Redis disponible: {deferred_queue_service.redis is not None}")
                
                if deferred_queue_service.redis:
                    try:
                        # Test de ping Redis
                        deferred_queue_service.redis.ping()
                        logger.info(f"[ENRICHMENT DIAGNOSTIC] Redis ping r√©ussi pour album {album_id}")
                    except Exception as ping_error:
                        logger.error(f"[ENRICHMENT DIAGNOSTIC] Redis ping √©chou√© pour album {album_id}: {ping_error}")
                
                success = deferred_queue_service.enqueue_task(
                    "deferred_enrichment",
                    task_data,
                    priority="normal",
                    delay_seconds=120  # D√©lai de 2 minutes pour les albums
                )

                if success:
                    logger.info(f"[ENRICHMENT] ‚úÖ T√¢che enrichissement enqueued pour album {album_id}")
                    enqueued_count += 1
                else:
                    # DIAGNOSTIC: Log d√©taill√© de l'√©chec
                    logger.error(f"[ENRICHMENT] ‚ùå √âchec enqueue t√¢che album {album_id}")
                    logger.error(f"[ENRICHMENT DIAGNOSTIC] Donn√©es qui ont √©chou√©: {task_data}")
                    logger.error(f"[ENRICHMENT DIAGNOSTIC] Taille des donn√©es: {len(str(task_data))} caract√®res")
                    
                    # V√©rifier l'√©tat de Redis apr√®s l'√©chec
                    if deferred_queue_service.redis:
                        try:
                            info = deferred_queue_service.redis.info()
                            logger.error(f"[ENRICHMENT DIAGNOSTIC] Redis info apr√®s √©chec: used_memory={info.get('used_memory', 'N/A')}")
                        except Exception as info_error:
                            logger.error(f"[ENRICHMENT DIAGNOSTIC] Impossible d'obtenir info Redis: {info_error}")
                    else:
                        logger.error(f"[ENRICHMENT DIAGNOSTIC] Redis non disponible lors de l'enqueue")

            except Exception as e:
                logger.error(f"[ENRICHMENT] Erreur v√©rification album {album_id}: {str(e)}")

        logger.info(f"[ENRICHMENT] Total t√¢ches enqueued pour albums: {enqueued_count}/{len(album_ids)}")

    except Exception as e:
        logger.error(f"[ENRICHMENT] Erreur g√©n√©rale enqueue albums: {str(e)}")


async def verify_musicbrainz_ids_in_tracks(client: httpx.AsyncClient, tracks_data: List[Dict]) -> None:
    """
    V√©rifie que les IDs MusicBrainz sont bien pr√©sents dans les donn√©es des tracks avant insertion.
    """
    logger.info("[DIAGNOSTIC MBID] V√©rification des IDs MusicBrainz dans les tracks avant insertion")
    for track in tracks_data:
        mb_ids = {
            'musicbrainz_id': track.get('musicbrainz_id'),
            'musicbrainz_albumid': track.get('musicbrainz_albumid'),
            'musicbrainz_artistid': track.get('musicbrainz_artistid'),
            'musicbrainz_albumartistid': track.get('musicbrainz_albumartistid')
        }
        logger.info(f"[DIAGNOSTIC MBID] Track '{track.get('title', 'unknown')}' - MBIDs: {mb_ids}")


async def verify_musicbrainz_ids_persistence(client: httpx.AsyncClient, tracks_data: List[Dict]) -> None:
    """
    V√©rifie que les IDs MusicBrainz sont bien persist√©s en base de donn√©es.
    """
    logger.info("[DIAGNOSTIC MBID] V√©rification de la persistance des IDs MusicBrainz en base")
    for track in tracks_data:
        track_path = track.get('path')
        if track_path:
            query = """
            query GetTrackMusicBrainzIDs($filePath: String!) {
                tracks(where: {file_path: $filePath}) {
                    musicbrainzId
                    musicbrainzAlbumid
                    musicbrainzArtistid
                    musicbrainzAlbumartistid
                }
            }
            """
            result = await execute_graphql_query(client, query, {"filePath": track_path})
            tracks_found = result.get("tracks", [])
            if tracks_found:
                track_in_db = tracks_found[0]
                mb_ids_in_db = {
                    'musicbrainz_id': track_in_db.get('musicbrainzId'),
                    'musicbrainz_albumid': track_in_db.get('musicbrainzAlbumid'),
                    'musicbrainz_artistid': track_in_db.get('musicbrainzArtistid'),
                    'musicbrainz_albumartistid': track_in_db.get('musicbrainzAlbumartistid')
                }
                logger.info(f"[DIAGNOSTIC MBID] Track '{track.get('title', 'unknown')}' - MBIDs en base: {mb_ids_in_db}")
            else:
                logger.error(f"[DIAGNOSTIC MBID] Track '{track.get('title', 'unknown')}' non trouv√©e en base")


async def resolve_album_for_track(track: Dict, artist_map: Dict, album_map: Dict, client: httpx.AsyncClient) -> Dict:
    """
    R√©sout l'album pour une track en utilisant les IDs MusicBrainz ou les informations de l'album.
    """
    resolved_track = dict(track)
    album_title = track.get('album_title') or track.get('album')
    artist_name = track.get('artist_name') or track.get('artist')

    # Utiliser les IDs MusicBrainz si disponibles
    mb_album_id = track.get('musicbrainz_albumid')
    mb_artist_id = track.get('musicbrainz_artistid') or track.get('musicbrainz_albumartistid')

    # DIAGNOSTIC: Log des donn√©es disponibles
    logger.debug(f"[RESOLVE_ALBUM] Track: '{track.get('title')}', Album: '{album_title}', Artist: '{artist_name}'")
    logger.debug(f"[RESOLVE_ALBUM] MB Album ID: {mb_album_id}, MB Artist ID: {mb_artist_id}")
    logger.debug(f"[RESOLVE_ALBUM] Album map keys count: {len(album_map)}, Artist map keys count: {len(artist_map)}")

    if mb_album_id:
        # Cl√© bas√©e sur MusicBrainz ID
        album_key = mb_album_id
        logger.info(f"[RESOLVE_ALBUM] Utilisation de MusicBrainz Album ID pour la r√©solution: {album_key}")
    else:
        # Cl√© bas√©e sur titre + ID artiste
        normalized_album_title = album_title.strip().lower() if album_title else None
        if normalized_album_title and artist_name:
            # R√©soudre l'artiste d'abord - chercher avec gestion de casse
            artist_id = None
            artist_key_found = None
            
            # Essayer d'abord la correspondance exacte
            if artist_name in artist_map:
                artist_id = artist_map[artist_name]['id']
                artist_key_found = artist_name
            else:
                # Recherche insensible √† la casse
                artist_name_lower = artist_name.lower()
                for key, data in artist_map.items():
                    if isinstance(key, str) and key.lower() == artist_name_lower:
                        artist_id = data['id']
                        artist_key_found = key
                        logger.debug(f"[RESOLVE_ALBUM] Artiste trouv√© via case-insensitive: '{artist_name}' -> '{key}' (ID: {artist_id})")
                        break
            
            if artist_id:
                album_key = (normalized_album_title, artist_id)
                logger.debug(f"[RESOLVE_ALBUM] Artiste '{artist_name}' r√©solu via '{artist_key_found}' -> ID {artist_id}")
            else:
                logger.error(f"[RESOLVE_ALBUM] Artiste '{artist_name}' non trouv√© dans artist_map. Keys disponibles: {list(artist_map.keys())[:10]}...")
                album_key = None
        else:
            logger.warning(f"[RESOLVE_ALBUM] Donn√©es insuffisantes pour cr√©er la cl√© d'album: title='{album_title}', artist='{artist_name}'")
            album_key = None

    # Recherche de l'album avec la cl√©
    if album_key:
        logger.debug(f"[RESOLVE_ALBUM] Recherche album avec cl√©: {album_key}")
        logger.debug(f"[RESOLVE_ALBUM] Type de cl√©: {type(album_key)}, Album map keys types: {[type(k) for k in list(album_map.keys())[:5]]}")
        
        if album_key in album_map:
            resolved_track['album_id'] = album_map[album_key]['id']
            logger.info(f"[RESOLVE_ALBUM] ‚úÖ Album r√©solu avec succ√®s: '{album_title}' -> ID {album_map[album_key]['id']} (cl√©: {album_key})")
        else:
            # Essayer de trouver l'album par titre uniquement si la cl√© compl√®te √©choue
            logger.warning(f"[RESOLVE_ALBUM] Album non trouv√© avec cl√© compl√®te: {album_key}")
            
            # Recherche alternative par titre seul (sans artist_id)
            found_alternative = False
            if not mb_album_id and normalized_album_title:
                for key, album_data in album_map.items():
                    if isinstance(key, tuple) and len(key) >= 1:
                        if key[0] == normalized_album_title:
                            resolved_track['album_id'] = album_data['id']
                            logger.info(f"[RESOLVE_ALBUM] ‚úÖ Album trouv√© via recherche alternative (titre seul): '{album_title}' -> ID {album_data['id']}")
                            found_alternative = True
                            break
            
            if not found_alternative:
                logger.error(f"[RESOLVE_ALBUM] ‚ùå Album non r√©solu pour '{album_title}'. Cl√© recherch√©e: {album_key}")
                logger.error(f"[RESOLVE_ALBUM] Album map keys (sample): {list(album_map.keys())[:10]}...")
                resolved_track['album_id'] = None
    else:
        logger.error(f"[RESOLVE_ALBUM] ‚ùå Impossible de cr√©er une cl√© d'album pour '{album_title}'")
        resolved_track['album_id'] = None

    return resolved_track


async def resolve_track_artist_id(track: Dict, artist_map: Dict) -> int:
    """
    R√©sout l'ID de l'artiste pour une track en utilisant artist_map.
    
    Args:
        track: Donn√©es de la track contenant artist_name ou musicbrainz_artistid/musicbrainz_albumartistid
        artist_map: Mapping des noms d'artistes vers leurs IDs
    
    Returns:
        L'ID de l'artiste (int) ou None si non trouv√©
    """
    artist_name = track.get('artist_name') or track.get('artist')
    
    # Essayer d'abord avec le nom d'artiste (recherche exacte)
    if artist_name and artist_name in artist_map:
        artist_id = artist_map[artist_name]['id']
        logger.debug(f"[RESOLVE_ARTIST] Artiste '{artist_name}' r√©solu via nom exact -> ID {artist_id}")
        return artist_id
    
    # Essayer avec le nom d'artiste en minuscules (recherche insensible √† la casse)
    if artist_name:
        artist_name_lower = artist_name.lower()
        for key, data in artist_map.items():
            if isinstance(key, str) and key.lower() == artist_name_lower:
                artist_id = data['id']
                logger.debug(f"[RESOLVE_ARTIST] Artiste '{artist_name}' r√©solu via nom (case-insensitive) -> ID {artist_id}")
                return artist_id
    
    # Essayer avec musicbrainz_artistid ou musicbrainz_albumartistid
    mb_artist_id = track.get('musicbrainz_artistid') or track.get('musicbrainz_albumartistid')
    if mb_artist_id:
        # Chercher par MusicBrainz ID dans artist_map
        for name, data in artist_map.items():
            if isinstance(data, dict) and data.get('musicbrainz_id') == mb_artist_id:
                logger.debug(f"[RESOLVE_ARTIST] Artiste MBID {mb_artist_id} r√©solu via MBID -> ID {data['id']}")
                return data['id']
    
    logger.warning(f"[RESOLVE_ARTIST] Impossible de r√©soudre l'artiste pour la track '{track.get('title', 'unknown')}' (nom recherch√©: '{artist_name}')")
    return None


async def process_genres_and_tags_for_tracks(client: httpx.AsyncClient, tracks_data: List[Dict]) -> None:
    """
    Traite les genres et tags pour les tracks avant leur insertion.
    Cr√©e les genres et tags manquants via l'API REST.

    Args:
        client: Client HTTP asynchrone
        tracks_data: Liste des donn√©es de tracks
    """
    try:
        logger.info(f"[TAGS] Traitement des genres et tags pour {len(tracks_data)} tracks")

        # Collecter tous les genres et tags uniques
        genres_to_create = set()
        genre_tags_to_create = set()
        mood_tags_to_create = set()

        for track in tracks_data:
            # Genres principaux (utiliser la liste splitt√©e si disponible)
            if track.get('genres') and isinstance(track['genres'], list):
                genres_to_create.update(track['genres'])
            elif track.get('genre'):
                # Fallback sur le genre original si pas de liste splitt√©e
                # Splitter les genres s√©par√©s par des virgules
                genre_string = track['genre'].strip()
                if ',' in genre_string:
                    # Splitter et nettoyer chaque genre
                    split_genres = [g.strip() for g in genre_string.split(',') if g.strip()]
                    genres_to_create.update(split_genres)
                else:
                    genres_to_create.add(genre_string)

            # Genre tags
            if track.get('genre_tags'):
                if isinstance(track['genre_tags'], list):
                    genre_tags_to_create.update(track['genre_tags'])

            # Mood tags
            if track.get('mood_tags'):
                if isinstance(track['mood_tags'], list):
                    mood_tags_to_create.update(track['mood_tags'])

        # Cr√©er les genres manquants
        for genre_name in genres_to_create:
            if genre_name:
                await create_or_get_genre(client, genre_name)

        # Cr√©er les genre tags manquants
        for tag_name in genre_tags_to_create:
            if tag_name:
                await create_or_get_genre_tag(client, tag_name)

        # Cr√©er les mood tags manquants
        for tag_name in mood_tags_to_create:
            if tag_name:
                await create_or_get_mood_tag(client, tag_name)

        logger.info(f"[TAGS] Genres cr√©√©s: {len(genres_to_create)}, Genre tags: {len(genre_tags_to_create)}, Mood tags: {len(mood_tags_to_create)}")

    except Exception as e:
        logger.error(f"[TAGS] Erreur lors du traitement des genres et tags: {str(e)}")
        # Ne pas lever d'exception pour ne pas bloquer l'insertion des tracks


async def verify_entities_presence(client: httpx.AsyncClient, inserted_counts: Dict[str, int],
                                   artists_data: List[Dict], albums_data: List[Dict], tracks_data: List[Dict]) -> None:
    """
    V√©rifie que toutes les entit√©s ins√©r√©es sont bien pr√©sentes en base de donn√©es.
    Utilise des requ√™tes cibl√©es pour √©viter les probl√®mes de performance et de timing.

    Args:
        client: Client HTTP asynchrone
        inserted_counts: Comptes des entit√©s ins√©r√©es
        artists_data: Donn√©es des artistes d'origine
        albums_data: Donn√©es des albums d'origine
        tracks_data: Donn√©es des tracks d'origine

    Raises:
        Exception: Si des entit√©s sont manquantes en base
    """
    try:
        missing_entities = []

        # R√©activer la v√©rification avec gestion am√©lior√©e des erreurs
        logger.info("[VERIFY] V√©rification des entit√©s r√©activ√©e avec gestion am√©lior√©e des erreurs")

        # V√©rifier les artistes avec endpoint REST (GraphQL ne supporte pas 'where')
        if inserted_counts['artists'] > 0:
            logger.info(f"[VERIFY] V√©rification cibl√©e de {len(artists_data)} artistes via REST API")
            for artist_data in artists_data:
                artist_name = artist_data.get('name')
                if artist_name:
                    try:
                        # Utiliser l'endpoint REST /artists pour v√©rifier (GraphQL ne supporte pas where)
                        response = await client.get("/api/artists/", params={"skip": 0, "limit": 1000}, follow_redirects=True)
                        if response.status_code == 200:
                            all_artists = response.json().get('results', [])
                            # Chercher l'artiste par nom
                            found = any(a.get('name') == artist_name for a in all_artists)
                            if not found:
                                missing_entities.append(f"Artiste: {artist_name}")
                                logger.error(f"[VERIFY] ‚ùå Artiste '{artist_name}' INTROUVABLE en base apr√®s insertion")
                            else:
                                logger.info(f"[VERIFY] ‚úÖ Artiste '{artist_name}' trouv√© via REST API")
                        else:
                            logger.warning(f"[VERIFY] Impossible de r√©cup√©rer la liste des artistes via REST: {response.status_code}")
                            # Fallback: supposer pr√©sent pour √©viter blocage
                            logger.info(f"[VERIFY] ‚úÖ Artiste '{artist_name}' suppos√© pr√©sent (fallback)")

                    except Exception as e:
                        logger.error(f"[VERIFY] ‚ùå Erreur v√©rification artiste '{artist_name}': {str(e)}")
                        logger.error(f"[VERIFY] D√©tails de l'erreur: {type(e).__name__}: {str(e)}")
                        missing_entities.append(f"Artiste: {artist_name} (erreur v√©rification)")

        # V√©rifier les albums avec endpoint REST (GraphQL ne supporte pas 'where')
        if inserted_counts['albums'] > 0:
            logger.info(f"[VERIFY] V√©rification cibl√©e de {len(albums_data)} albums via REST API")
            for album_data in albums_data:
                album_title = album_data.get('title')
                if album_title:
                    try:
                        # Utiliser l'endpoint REST /albums pour v√©rifier (GraphQL ne supporte pas where)
                        response = await client.get("/api/albums", params={"skip": 0, "limit": 1000})
                        if response.status_code == 200:
                            all_albums = response.json().get('results', [])
                            # Chercher l'album par titre
                            found = any(a.get('title') == album_title for a in all_albums)
                            if not found:
                                missing_entities.append(f"Album: {album_title}")
                                logger.error(f"[VERIFY] ‚ùå Album '{album_title}' INTROUVABLE en base apr√®s insertion")
                            else:
                                logger.info(f"[VERIFY] ‚úÖ Album '{album_title}' trouv√© via REST API")
                        else:
                            logger.warning(f"[VERIFY] Impossible de r√©cup√©rer la liste des albums via REST: {response.status_code}")
                            # Fallback: supposer pr√©sent pour √©viter blocage
                            logger.info(f"[VERIFY] ‚úÖ Album '{album_title}' suppos√© pr√©sent (fallback)")

                    except Exception as e:
                        logger.warning(f"[VERIFY] Erreur v√©rification album '{album_title}': {str(e)}")
                        missing_entities.append(f"Album: {album_title} (erreur v√©rification)")

        # V√©rifier les tracks avec requ√™te cibl√©e
        if inserted_counts['tracks'] > 0:
            logger.info(f"[VERIFY] V√©rification cibl√©e de {len(tracks_data)} tracks")

            # DIAGNOSTIC: Statistiques des m√©tadonn√©es manquantes
            metadata_missing_stats = {
                'bpm': 0, 'key': 0, 'scale': 0, 'danceability': 0,
                'mood_happy': 0, 'mood_aggressive': 0, 'mood_party': 0, 'mood_relaxed': 0,
                'instrumental': 0, 'acoustic': 0, 'tonal': 0, 'genre_main': 0,
                'camelot_key': 0, 'musicbrainz_albumid': 0, 'musicbrainz_artistid': 0,
                'musicbrainz_albumartistid': 0, 'musicbrainz_genre': 0, 'acoustid_fingerprint': 0
            }

            for track_data in tracks_data:
                track_path = track_data.get('path')
                if track_path:
                    try:
                        # DIAGNOSTIC: Utiliser le bon champ 'path' au lieu de 'filePath'
                        logger.info("[VERIFY] üîç Utilisation du champ 'path' pour la v√©rification")
                        logger.info(f"[VERIFY] üîç Track '{track_path}' - v√©rification avec champ 'path'")

                        # Requ√™te sp√©cifique pour cette track - utiliser le champ correct 'path'
                        query = """
                        query GetTrackByPath($filePath: String!) {
                            tracks(where: {file_path: $filePath}) {
                                id
                                path
                                bpm
                                key
                                scale
                                danceability
                                moodHappy
                                moodAggressive
                                moodParty
                                moodRelaxed
                                instrumental
                                acoustic
                                tonal
                                genreMain
                                camelotKey
                                musicbrainzAlbumid
                                musicbrainzArtistid
                                musicbrainzAlbumartistid
                                musicbrainzId
                                acoustidFingerprint
                            }
                        }
                        """
                        result = await execute_graphql_query(client, query, {"filePath": track_path})
                        tracks_found = result.get("tracks", [])
                        if not tracks_found:
                            missing_entities.append(f"Track: {track_path}")
                            logger.error(f"[VERIFY] ‚ùå Track '{track_path}' INTROUVABLE en base apr√®s insertion")
                        else:
                            track_in_db = tracks_found[0]
                            logger.info(f"[VERIFY] ‚úÖ Track '{track_path}' trouv√©e avec ID {track_in_db['id']}")
                            
                            # DIAGNOSTIC: V√©rifier les champs de m√©tadonn√©es manquants
                            logger.info(f"[DIAGNOSTIC META] Track ID {track_in_db['id']} - M√©tadonn√©es manquantes:")
                            
                            # V√©rifier chaque champ de m√©tadonn√©es
                            metadata_fields = {
                                'bpm': track_in_db.get('bpm'),
                                'key': track_in_db.get('key'),
                                'scale': track_in_db.get('scale'),
                                'danceability': track_in_db.get('danceability'),
                                'mood_happy': track_in_db.get('moodHappy'),
                                'mood_aggressive': track_in_db.get('moodAggressive'),
                                'mood_party': track_in_db.get('moodParty'),
                                'mood_relaxed': track_in_db.get('moodRelaxed'),
                                'instrumental': track_in_db.get('instrumental'),
                                'acoustic': track_in_db.get('acoustic'),
                                'tonal': track_in_db.get('tonal'),
                                'genre_main': track_in_db.get('genreMain'),
                                'camelot_key': track_in_db.get('camelotKey'),
                                'musicbrainz_albumid': track_in_db.get('musicbrainzAlbumid'),
                                'musicbrainz_artistid': track_in_db.get('musicbrainzArtistid'),
                                'musicbrainz_albumartistid': track_in_db.get('musicbrainzAlbumartistid'),
                                'musicbrainz_genre': track_in_db.get('musicbrainzId'),
                                'acoustid_fingerprint': track_in_db.get('acoustidFingerprint')
                            }
                            
                            # Compter les champs manquants
                            for field, value in metadata_fields.items():
                                if value is None or value == '':
                                    metadata_missing_stats[field] += 1
                                    logger.warning(f"[DIAGNOSTIC META]   - {field}: MANQUANT (None/Empty)")
                                else:
                                    logger.info(f"[DIAGNOSTIC META]   - {field}: OK ({value})")
                            
                            # V√©rifier album_id sp√©cifiquement
                            album_id = track_in_db.get('album_id')
                            if album_id is None:
                                logger.error(f"[DIAGNOSTIC ALBUM] ‚ùå Track '{track_path}' SANS album_id")
                            else:
                                logger.info(f"[DIAGNOSTIC ALBUM] ‚úÖ Track '{track_path}' avec album_id: {album_id}")
                    except Exception as e:
                        logger.warning(f"[VERIFY] Erreur v√©rification track '{track_path}': {str(e)}")
                        logger.error(f"[VERIFY] D√©tails de l'erreur: {type(e).__name__}: {str(e)}")
                        missing_entities.append(f"Track: {track_path} (erreur v√©rification)")
            
            # Rapport final des m√©tadonn√©es manquantes
            logger.info("[DIAGNOSTIC META] RAPPORT FINAL - M√©tadonn√©es manquantes:")
            total_tracks = len(tracks_data)
            for field, count in metadata_missing_stats.items():
                percentage = (count / total_tracks * 100) if total_tracks > 0 else 0
                logger.info(f"[DIAGNOSTIC META]   - {field}: {count}/{total_tracks} tracks ({percentage:.1f}%)")
            
            # Rapport sp√©cial pour album_id (calcul s√©par√©)
            album_id_missing = sum(1 for track_data in tracks_data if not track_data.get('album_id'))
            album_id_percentage = (album_id_missing / total_tracks * 100) if total_tracks > 0 else 0
            logger.info(f"[DIAGNOSTIC ALBUM] RAPPORT FINAL - Tracks sans album_id: {album_id_missing}/{total_tracks} ({album_id_percentage:.1f}%)")

        # Si des entit√©s sont manquantes, lever une exception pour d√©clencher un retry
        if missing_entities:
            error_msg = f"Entit√©s manquantes en base apr√®s insertion: {missing_entities}"
            logger.error(f"[VERIFY] {error_msg}")
            logger.error(f"[VERIFY] Comptes ins√©r√©s: {inserted_counts}")
            logger.error(f"[VERIFY] Donn√©es artistes: {len(artists_data)}, albums: {len(albums_data)}, tracks: {len(tracks_data)}")
            raise Exception(error_msg)

        logger.info("[VERIFY] Toutes les entit√©s v√©rifi√©es avec succ√®s en base")

    except Exception as e:
        logger.error(f"[VERIFY] Erreur lors de la v√©rification des entit√©s: {str(e)}")
        raise


async def _insert_batch_direct_async(self, insertion_data: Dict[str, Any]):
    """Ins√®re en base de donn√©es via l'API HTTP uniquement.

    Utilise l'entity_manager pour la r√©solution automatique des r√©f√©rences.
    Optimis√©e pour Raspberry Pi : batches plus petits, timeouts r√©duits.

    Args:
        insertion_data: Donn√©es group√©es pr√™tes pour insertion

    Returns:
        R√©sultat de l'insertion
    """
    start_time = time.time()
    task_id = self.request.id

    try:
        logger.info(f"[INSERT] D√©marrage insertion: {len(insertion_data.get('artists', []))} artistes, {len(insertion_data.get('albums', []))} albums, {len(insertion_data.get('tracks', []))} pistes")
        logger.info(f"[INSERT] Task ID: {task_id}")
        logger.info("[INSERT] VRAIE IMPL√âMENTATION - Utilisation entity_manager via GraphQL API")

        # R√©cup√©rer les donn√©es
        artists_data = insertion_data.get('artists', [])
        albums_data = insertion_data.get('albums', [])
        tracks_data = insertion_data.get('tracks', [])

        if not tracks_data and not artists_data and not albums_data:
            logger.warning("[INSERT] Aucune donn√©e √† ins√©rer")
            return {
                'task_id': task_id,
                'success': True,
                'artists_inserted': 0,
                'albums_inserted': 0,
                'tracks_inserted': 0
            }

        # Configuration pour les appels API
        library_api_url = os.getenv("LIBRARY_API_URL", "http://api:8001")

        # Configuration client HTTP asynchrone optimis√©e pour Raspberry Pi
        async with httpx.AsyncClient(
            base_url=library_api_url,
            timeout=httpx.Timeout(120.0),  # 2 minutes timeout
            follow_redirects=True,  # Suivre les redirections (n√©cessaire pour les 307)
            limits=httpx.Limits(
                max_keepalive_connections=10,
                max_connections=20,
                keepalive_expiry=120.0
            )
        ) as client:

            # Cr√©er le client asynchrone pour entity_manager
            async def run_insertion():
                inserted_counts = {
                    'artists': 0,
                    'albums': 0,
                    'tracks': 0
                }

                # Initialiser artist_map m√™me si aucun artiste n'est fourni
                artist_map = {}

                # √âtape 1: Traitement des artistes via entity_manager
                if artists_data:
                    logger.info(f"[INSERT] Traitement de {len(artists_data)} artistes via entity_manager")
                    logger.debug(f"[INSERT] Artistes √† traiter: {[a.get('name', 'unknown') for a in artists_data]}")
                    artist_map = await create_or_get_artists_batch(client, artists_data)
                    inserted_counts['artists'] = len(artist_map)
                    logger.info(f"[INSERT] Artistes trait√©s: {len(artist_map)}")
                    logger.debug(f"[INSERT] Artist map keys: {list(artist_map.keys())}")

                    # Normaliser les cl√©s du artist_map pour une recherche insensible √† la casse
                    normalized_artist_map = {}
                    for key, value in artist_map.items():
                        normalized_key = key.lower() if isinstance(key, str) else key
                        normalized_artist_map[normalized_key] = value
                        # Conserver aussi la cl√© originale pour compatibilit√©
                        if isinstance(key, str) and key != normalized_key:
                            normalized_artist_map[key] = value
                    artist_map = normalized_artist_map
                    logger.debug(f"[INSERT] Artist map normalis√©: {list(artist_map.keys())}")

                    # D√©clencher callback pour traitement des images d'artistes
                    if artist_map:
                        artist_ids = [artist.get('id') for artist in artist_map.values() if artist.get('id')]
                        if artist_ids:
                            await on_artists_inserted_callback(artist_ids)
                            # Enqueue t√¢ches d'enrichissement pour les artistes sans covers
                            await enqueue_enrichment_tasks_for_artists(client, artist_ids, library_api_url)

                # √âtape 2: Traitement des albums via entity_manager
                if albums_data:
                    logger.info(f"[INSERT] Traitement de {len(albums_data)} albums via entity_manager")
                    
                    # DIAGNOSTIC: Log des albums avant r√©solution
                    logger.info(f"[INSERT] Albums √† traiter (sample): {albums_data[:3]}")

                    # R√©soudre album_artist_id pour chaque album
                    resolved_albums_data = []
                    albums_skipped = []
                    for album in albums_data:
                        resolved_album = dict(album)
                        album_artist_name = album.get('album_artist_name')
                        album_title = album.get('title', 'Unknown')
                        
                        logger.debug(f"[INSERT] R√©solution album '{album_title}' avec artist_name='{album_artist_name}'")
                        
                        # Recherche insensible √† la casse de l'artiste
                        album_artist_id = None
                        artist_key_used = None
                        
                        if album_artist_name:
                            # Essayer d'abord la correspondance exacte
                            if album_artist_name in artist_map:
                                album_artist_id = artist_map[album_artist_name]['id']
                                artist_key_used = album_artist_name
                                logger.debug(f"[INSERT] Artiste album '{album_artist_name}' trouv√© (exact) -> ID {album_artist_id}")
                            else:
                                # Recherche insensible √† la casse
                                album_artist_lower = album_artist_name.lower()
                                for key, data in artist_map.items():
                                    if isinstance(key, str) and key.lower() == album_artist_lower:
                                        album_artist_id = data['id']
                                        artist_key_used = key
                                        logger.debug(f"[INSERT] Artiste album '{album_artist_name}' trouv√© (case-insensitive via '{key}') -> ID {album_artist_id}")
                                        break
                        
                        if album_artist_id:
                            resolved_album['album_artist_id'] = album_artist_id
                            logger.info(f"[INSERT] ‚úÖ Album '{album_title}' r√©solu avec artist_id={album_artist_id} (via '{artist_key_used}')")
                        else:
                            logger.warning(f"[INSERT] ‚ö†Ô∏è Artiste '{album_artist_name}' non trouv√© pour album '{album_title}', tentative de cr√©ation")
                            # Essayer de cr√©er l'artiste si pas trouv√©
                            if album_artist_name:
                                single_artist_data = [{'name': album_artist_name}]
                                temp_artist_map = await create_or_get_artists_batch(client, single_artist_data)
                                if temp_artist_map:
                                    artist_id = list(temp_artist_map.values())[0]['id']
                                    resolved_album['album_artist_id'] = artist_id
                                    # Ajouter au artist_map principal
                                    artist_map[album_artist_name] = list(temp_artist_map.values())[0]
                                    inserted_counts['artists'] += 1
                                    logger.info(f"[INSERT] ‚úÖ Artiste '{album_artist_name}' cr√©√© √† la vol√©e -> ID {artist_id}")
                                else:
                                    logger.error(f"[INSERT] ‚ùå Impossible de cr√©er l'artiste '{album_artist_name}' pour l'album '{album_title}'")
                                    albums_skipped.append(album_title)
                                    continue  # Passer cet album - on ne peut pas cr√©er d'album sans artiste
                            else:
                                logger.error(f"[INSERT] ‚ùå Album '{album_title}' sans nom d'artiste, impossible de cr√©er")
                                albums_skipped.append(album_title)
                                continue  # Passer cet album

                        resolved_albums_data.append(resolved_album)
                        logger.debug(f"[INSERT] Album r√©solu ajout√©: {resolved_album}")

                    if albums_skipped:
                        logger.warning(f"[INSERT] {len(albums_skipped)} albums ignor√©s faute d'artiste: {albums_skipped[:10]}")

                    # DIAGNOSTIC: Log des albums r√©solus avant envoi
                    logger.info(f"[INSERT] {len(resolved_albums_data)} albums pr√™ts pour cr√©ation (sur {len(albums_data)} initiaux)")
                    if resolved_albums_data:
                        logger.debug(f"[INSERT] Sample albums r√©solus: {resolved_albums_data[:3]}")

                    album_map = await create_or_get_albums_batch(client, resolved_albums_data)
                    inserted_counts['albums'] = len(album_map)
                    logger.info(f"[INSERT] Albums trait√©s: {len(album_map)} (attendus: {len(resolved_albums_data)})")
                    
                    # DIAGNOSTIC: V√©rifier si tous les albums ont √©t√© cr√©√©s
                    if len(album_map) < len(resolved_albums_data):
                        logger.error(f"[INSERT] ‚ö†Ô∏è DISCR√âPANCE: {len(resolved_albums_data)} albums attendus mais {len(album_map)} retourn√©s")
                        logger.error(f"[INSERT] Albums manquants potentiels - v√©rifier les logs entity_manager")

                    # D√©clencher callback pour traitement des covers d'albums
                    if album_map:
                        album_ids = [album.get('id') for album in album_map.values() if album.get('id')]
                        if album_ids:
                            logger.info(f"[INSERT] D√©clenchement callbacks pour {len(album_ids)} albums")
                            await on_albums_inserted_callback(album_ids)
                            # Enqueue t√¢ches d'enrichissement pour les albums sans covers
                            await enqueue_enrichment_tasks_for_albums(client, album_ids, library_api_url)

                # √âtape 3: Traitement des tracks via entity_manager
                if tracks_data:
                    logger.info(f"[INSERT] Traitement de {len(tracks_data)} tracks via entity_manager")

                    # S'assurer qu'un artiste par d√©faut existe dans artist_map
                    default_artist_name = 'Unknown Artist'
                    if default_artist_name not in artist_map:
                        logger.warning(f"[INSERT] Artiste par d√©faut '{default_artist_name}' non trouv√©, cr√©ation...")
                        default_artist_data = [{'name': default_artist_name}]
                        temp_artist_map = await create_or_get_artists_batch(client, default_artist_data)
                        if temp_artist_map:
                            artist_map[default_artist_name] = list(temp_artist_map.values())[0]
                            inserted_counts['artists'] += 1
                            logger.info(f"[INSERT] Artiste par d√©faut cr√©√© avec ID {artist_map[default_artist_name]['id']}")
                        else:
                            logger.error("[INSERT] Impossible de cr√©er l'artiste par d√©faut, certaines tracks pourraient √©chouer")

                    # R√©soudre les r√©f√©rences artiste/album pour les tracks
                    resolved_tracks_data = []
                    skipped_tracks = []
                    
                    # DIAGNOSTIC: Log de l'album_map avant r√©solution des tracks
                    logger.info(f"[INSERT] R√©solution des albums pour {len(tracks_data)} tracks")
                    logger.debug(f"[INSERT] Album map keys disponibles: {list(album_map.keys())[:10]}...")
                    
                    for track in tracks_data:
                        track_title = track.get('title', 'unknown')
                        
                        # R√©soudre track_artist_id d'abord
                        track_artist_id = await resolve_track_artist_id(track, artist_map)
                        
                        # Si pas d'artiste r√©solu, utiliser l'artiste par d√©faut
                        if not track_artist_id and default_artist_name in artist_map:
                            track_artist_id = artist_map[default_artist_name]['id']
                            logger.warning(f"[INSERT] Track '{track_title}' sans artiste, utilisation de l'artiste par d√©faut (ID: {track_artist_id})")
                        
                        # V√©rifier que track_artist_id est valide (requis par GraphQL)
                        if not track_artist_id:
                            logger.error(f"[INSERT] Track '{track_title}' ignor√©e - impossible de r√©soudre track_artist_id m√™me avec fallback")
                            skipped_tracks.append(track_title)
                            continue
                        
                        # R√©soudre l'album pour cette track
                        resolved_track = await resolve_album_for_track(track, artist_map, album_map, client)
                        
                        # Ajouter track_artist_id r√©solu (toujours pr√©sent maintenant)
                        resolved_track['track_artist_id'] = track_artist_id
                        resolved_tracks_data.append(resolved_track)
                        
                        # Log du r√©sultat de r√©solution d'album
                        album_id_resolved = resolved_track.get('album_id')
                        if album_id_resolved:
                            logger.debug(f"[INSERT] ‚úÖ Track '{track_title}' -> album_id={album_id_resolved}")
                        else:
                            logger.warning(f"[INSERT] ‚ö†Ô∏è Track '{track_title}' sans album_id (album='{track.get('album')}')")
                    
                    if skipped_tracks:
                        logger.warning(f"[INSERT] {len(skipped_tracks)} tracks ignor√©es: {skipped_tracks[:10]}")
                    
                    # DIAGNOSTIC: Statistiques de r√©solution d'albums
                    tracks_with_album = sum(1 for t in resolved_tracks_data if t.get('album_id'))
                    tracks_without_album = len(resolved_tracks_data) - tracks_with_album
                    logger.info(f"[INSERT] Statistiques album resolution: {tracks_with_album} avec album, {tracks_without_album} sans album")

                    # V√©rifier les IDs MusicBrainz avant l'insertion des tracks
                    await verify_musicbrainz_ids_in_tracks(client, resolved_tracks_data)

                    # Traiter les genres et tags AVANT l'insertion des tracks
                    logger.info("[INSERT] Traitement des genres et tags avant insertion tracks")
                    await process_genres_and_tags_for_tracks(client, resolved_tracks_data)

                    processed_tracks = await create_or_update_tracks_batch(client, resolved_tracks_data)
                    inserted_counts['tracks'] = len(processed_tracks)
                    
                    # DIAGNOSTIC: Statistiques des album_id
                    album_id_stats = {'with_album_id': 0, 'without_album_id': 0}
                    for track in processed_tracks:
                        if track.get('album_id'):
                            album_id_stats['with_album_id'] += 1
                        else:
                            album_id_stats['without_album_id'] += 1
                    
                    logger.info("[DIAGNOSTIC ALBUM] Statistiques apr√®s insertion:")
                    logger.info(f"[DIAGNOSTIC ALBUM] - Tracks avec album_id: {album_id_stats['with_album_id']}")
                    logger.info(f"[DIAGNOSTIC ALBUM] - Tracks sans album_id: {album_id_stats['without_album_id']}")
                    logger.info(f"[DIAGNOSTIC ALBUM] Tracks trait√©s: {len(processed_tracks)}")

                    # D√©clencher callback pour traitement des images depuis tracks
                    if processed_tracks:
                        await on_tracks_inserted_callback(processed_tracks)

                        # ENQUEUE AUDIO ENRICHMENT TASKS POUR LES TRACKS
                        logger.info(f"[ENRICHMENT] Enqueue t√¢ches d'enrichissement audio pour {len(processed_tracks)} tracks")
                        if processed_tracks:
                            # Enqueue chaque track individuellement avec son file_path
                            enqueued_count = 0
                            for track in processed_tracks:
                                track_id = track.get('id')
                                file_path = track.get('path')  # Le chemin du fichier
                                if track_id and file_path:
                                    # DIAGNOSTIC: Logs d√©taill√©s pour les tracks audio
                                    task_data = {
                                        "type": "track_audio",  # Format attendu par le worker
                                        "id": track_id,
                                        "file_path": file_path
                                    }
                                    
                                    logger.info(f"[ENRICHMENT DIAGNOSTIC] Tentative enqueue audio track {track_id} avec donn√©es: {task_data}")
                                    logger.info(f"[ENRICHMENT DIAGNOSTIC] Redis disponible: {deferred_queue_service.redis is not None}")
                                    
                                    success = deferred_queue_service.enqueue_task(
                                        "deferred_enrichment",
                                        task_data,
                                        priority="low",
                                        delay_seconds=30 + (enqueued_count % 10) * 5  # D√©lai progressif pour √©viter surcharge
                                    )
                                    if success:
                                        enqueued_count += 1
                                    else:
                                        # DIAGNOSTIC: Log d√©taill√© de l'√©chec pour les tracks
                                        logger.error(f"[ENRICHMENT] ‚ùå √âchec enqueue audio pour track {track_id}")
                                        logger.error(f"[ENRICHMENT DIAGNOSTIC] Donn√©es audio qui ont √©chou√©: {task_data}")
                                        logger.error(f"[ENRICHMENT DIAGNOSTIC] Taille des donn√©es: {len(str(task_data))} caract√®res")
                                        
                                        # V√©rifier l'√©tat de Redis apr√®s l'√©chec
                                        if deferred_queue_service.redis:
                                            try:
                                                info = deferred_queue_service.redis.info()
                                                logger.error(f"[ENRICHMENT DIAGNOSTIC] Redis info apr√®s √©chec audio: used_memory={info.get('used_memory', 'N/A')}")
                                            except Exception as info_error:
                                                logger.error(f"[ENRICHMENT DIAGNOSTIC] Impossible d'obtenir info Redis: {info_error}")
                                        else:
                                            logger.error(f"[ENRICHMENT DIAGNOSTIC] Redis non disponible lors de l'enqueue audio")
                            logger.info(f"[ENRICHMENT] ‚úÖ {enqueued_count}/{len(processed_tracks)} t√¢ches audio enqueued")

                return inserted_counts

            # === DIAGNOSTIC M√âTADONN√âES MANQUANTES (PR√â-INSERTION) ===
            if tracks_data:
                logger.info("[DIAGNOSTIC PRE-INSERT] Analyse des m√©tadonn√©es manquantes dans les tracks AVANT insertion")
                
                metadata_missing_stats = {
                    'bpm': 0, 'key': 0, 'scale': 0, 'danceability': 0,
                    'mood_happy': 0, 'mood_aggressive': 0, 'mood_party': 0, 'mood_relaxed': 0,
                    'instrumental': 0, 'acoustic': 0, 'tonal': 0, 'genre_main': 0,
                    'camelot_key': 0, 'musicbrainz_albumid': 0, 'musicbrainz_artistid': 0,
                    'musicbrainz_albumartistid': 0, 'musicbrainz_genre': 0, 'acoustid_fingerprint': 0
                }
                
                tracks_without_album = 0
                
                for track in tracks_data:
                    # V√©rifier chaque champ de m√©tadonn√©es
                    for field in metadata_missing_stats.keys():
                        value = track.get(field)
                        if value is None or value == '' or (isinstance(value, str) and not value.strip()):
                            metadata_missing_stats[field] += 1
                    
                    # V√©rifier album_id (pas dans metadata_missing_stats car sp√©cifique)
                    if not track.get('album_id'):
                        tracks_without_album += 1
                
                # Rapport d√©taill√© des m√©tadonn√©es manquantes
                total_tracks = len(tracks_data)
                logger.info("[DIAGNOSTIC PRE-INSERT] RAPPORT M√âTADONN√âES MANQUANTES - AVANT INSERTION:")
                for field, count in metadata_missing_stats.items():
                    percentage = (count / total_tracks * 100) if total_tracks > 0 else 0
                    logger.info(f"[DIAGNOSTIC PRE-INSERT]   - {field}: {count}/{total_tracks} tracks ({percentage:.1f}%)")
                
                album_percentage = (tracks_without_album / total_tracks * 100) if total_tracks > 0 else 0
                logger.info(f"[DIAGNOSTIC PRE-INSERT]   - album_id: {tracks_without_album}/{total_tracks} tracks ({album_percentage:.1f}%)")
                
                logger.info("[DIAGNOSTIC PRE-INSERT] Fin analyse pr√©-insertion")

            # Ex√©cuter l'insertion asynchrone
            inserted_counts = await run_insertion()

            # V√©rification de la persistance des IDs MusicBrainz apr√®s insertion
            await verify_musicbrainz_ids_persistence(client, tracks_data)

            # V√©rification de la pr√©sence des entit√©s en base apr√®s insertion
            await verify_entities_presence(client, inserted_counts, artists_data, albums_data, tracks_data)

            # M√©triques finales
            total_time = time.time() - start_time

            logger.info(f"[INSERT] Insertion termin√©e: {inserted_counts} en {total_time:.2f}s")

            # Publier les m√©triques
            publish_event("progress", {
                "type": "progress",
                "task_id": task_id,
                "step": "Insertion termin√©e",
                "current": inserted_counts['tracks'],
                "total": inserted_counts['tracks'],
                "percent": 100,
                "artists_inserted": inserted_counts['artists'],
                "albums_inserted": inserted_counts['albums'],
                "tracks_inserted": inserted_counts['tracks'],
                "insertion_time": total_time,
                "insertions_per_second": sum(inserted_counts.values()) / total_time if total_time > 0 else 0
            }, channel="progress")

            result = {
                'task_id': task_id,
                'success': True,
                **inserted_counts,
                'insertion_time': total_time,
                'insertions_per_second': sum(inserted_counts.values()) / total_time if total_time > 0 else 0
            }

            return result

    except Exception as e:
        error_time = time.time() - start_time
        logger.error(f"[INSERT] Erreur insertion apr√®s {error_time:.2f}s: {str(e)}")

        publish_event("progress", {
            "type": "progress",
            "task_id": task_id,
            "step": f"Erreur d'insertion: {str(e)}",
            "error": str(e),
            "duration": error_time
        }, channel="progress")

        raise
