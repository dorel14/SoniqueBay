#!/usr/bin/env python3
"""
SCRIPT DE TEST DE DÃ‰PLOIEMENT POUR L'OPTIMISATION DU SCAN

Test complet du systÃ¨me optimisÃ© avant dÃ©ploiement en production.
Valide que toutes les optimisations fonctionnent correctement ensemble.
"""

import asyncio
import subprocess
import sys
import os
import time
from pathlib import Path

# Ajouter les chemins nÃ©cessaires
sys.path.append('backend_worker')
sys.path.append('tests')


class DeploymentTest:
    """Classe de test de dÃ©ploiement."""

    def __init__(self):
        self.results = []
        self.errors = []

    def log(self, message, status="INFO"):
        """Log avec timestamp."""
        timestamp = time.strftime("%H:%M:%S")
        print(f"[{timestamp}] {status}: {message}")

        if status == "ERROR":
            self.errors.append(message)

    def run_command(self, command, description, timeout=60):
        """ExÃ©cute une commande systÃ¨me."""
        self.log(f"ExÃ©cution: {description}")
        self.log(f"Commande: {command}")

        try:
            result = subprocess.run(
                command,
                shell=True,
                capture_output=True,
                text=True,
                timeout=timeout,
                cwd=os.getcwd()
            )

            if result.returncode == 0:
                self.log(f"âœ“ {description} rÃ©ussi", "SUCCESS")
                return True, result.stdout
            else:
                self.log(f"âœ— {description} Ã©chouÃ©: {result.stderr}", "ERROR")
                return False, result.stderr

        except subprocess.TimeoutExpired:
            self.log(f"âœ— {description} timeout aprÃ¨s {timeout}s", "ERROR")
            return False, "Timeout"
        except Exception as e:
            self.log(f"âœ— {description} exception: {e}", "ERROR")
            return False, str(e)

    def test_python_environment(self):
        """Test de l'environnement Python."""
        self.log("Test environnement Python...")

        # VÃ©rifier la version Python
        success, output = self.run_command(
            "python --version",
            "VÃ©rification version Python"
        )

        if success:
            self.log(f"Version Python: {output.strip()}")

            # VÃ©rifier les modules requis
            required_modules = [
                'celery', 'redis', 'sqlalchemy', 'fastapi',
                'mutagen', 'librosa', 'httpx'
            ]

            for module in required_modules:
                success, _ = self.run_command(
                    f"python -c \"import {module}; print('{module} OK')\"",
                    f"Test module {module}"
                )

            return True
        return False

    def test_celery_configuration(self):
        """Test de la configuration Celery."""
        self.log("Test configuration Celery...")

        try:
            from backend_worker.celery_app import task_queues

            self.log("âœ“ Celery importÃ© avec succÃ¨s")
            self.log(f"âœ“ {len(task_queues)} queues configurÃ©es")

            # VÃ©rifier les nouvelles queues
            required_queues = ['scan', 'extract', 'batch', 'insert']
            for queue in required_queues:
                if queue in task_queues:
                    self.log(f"  âœ“ Queue '{queue}' disponible")
                else:
                    self.log(f"  âœ— Queue '{queue}' manquante", "ERROR")
                    return False

            return True

        except Exception as e:
            self.log(f"âœ— Erreur configuration Celery: {e}", "ERROR")
            return False

    def test_optimized_tasks(self):
        """Test des nouvelles tÃ¢ches optimisÃ©es."""
        self.log("Test tÃ¢ches optimisÃ©es...")

        try:
            # Importer toutes les nouvelles tÃ¢ches
            from backend_worker.background_tasks.optimized_scan import scan_directory_parallel
            from backend_worker.background_tasks.optimized_extract import extract_metadata_batch
            from backend_worker.background_tasks.optimized_batch import batch_entities
            from backend_worker.background_tasks.optimized_insert import insert_batch_optimized

            self.log("âœ“ Toutes les tÃ¢ches optimisÃ©es importÃ©es")

            # VÃ©rifier les propriÃ©tÃ©s des tÃ¢ches
            tasks_to_check = [
                (scan_directory_parallel, 'scan'),
                (extract_metadata_batch, 'extract'),
                (batch_entities, 'batch'),
                (insert_batch_optimized, 'insert')
            ]

            for task, expected_queue in tasks_to_check:
                if hasattr(task, 'queue') and task.queue == expected_queue:
                    self.log(f"  âœ“ {task.name} â†’ queue '{expected_queue}'")
                else:
                    self.log(f"  âœ— {task.name} mal configurÃ©e", "ERROR")
                    return False

            return True

        except Exception as e:
            self.log(f"âœ— Erreur tÃ¢ches optimisÃ©es: {e}", "ERROR")
            return False

    def test_database_connection(self):
        """Test de connexion Ã  la base de donnÃ©es."""
        self.log("Test connexion base de donnÃ©es...")

        try:
            from sqlalchemy import create_engine, text

            # Utiliser SQLite pour les tests
            db_path = "backend/library_api/data/music.db"
            if not os.path.exists(db_path):
                self.log(f"Base de donnÃ©es non trouvÃ©e: {db_path}", "ERROR")
                return False

            engine = create_engine(f"sqlite:///{db_path}")

            with engine.connect() as conn:
                result = conn.execute(text("SELECT COUNT(*) FROM tracks"))
                count = result.scalar()
                self.log(f"âœ“ Connexion DB OK - {count} pistes dans la base")

            return True

        except Exception as e:
            self.log(f"âœ— Erreur connexion DB: {e}", "ERROR")
            return False

    def test_redis_connection(self):
        """Test de connexion Redis."""
        self.log("Test connexion Redis...")

        try:
            import redis

            # Configuration Redis
            redis_url = os.getenv('CELERY_BROKER_URL', 'redis://localhost:6379/0')

            if 'redis://' not in redis_url:
                self.log("Redis non configurÃ©, test ignorÃ©")
                return True

            r = redis.Redis.from_url(redis_url)
            r.ping()

            self.log("âœ“ Connexion Redis OK")
            return True

        except Exception as e:
            self.log(f"âœ— Erreur connexion Redis: {e}", "ERROR")
            return False

    def test_docker_compose(self):
        """Test de la configuration Docker Compose."""
        self.log("Test configuration Docker Compose...")

        compose_file = "docker-compose-scan-optimized.yml"
        if not os.path.exists(compose_file):
            self.log(f"Fichier Docker Compose non trouvÃ©: {compose_file}", "ERROR")
            return False

        # VÃ©rifier le contenu du fichier
        with open(compose_file, 'r') as f:
            content = f.read()

        # VÃ©rifier les services requis
        required_services = ['redis', 'scan-worker', 'extract-worker', 'batch-worker', 'insert-worker']

        for service in required_services:
            if service in content:
                self.log(f"  âœ“ Service '{service}' trouvÃ©")
            else:
                self.log(f"  âœ— Service '{service}' manquant", "ERROR")
                return False

        self.log("âœ“ Configuration Docker Compose OK")
        return True

    def test_file_structure(self):
        """Test de la structure des fichiers."""
        self.log("Test structure des fichiers...")

        # VÃ©rifier les fichiers crÃ©Ã©s
        required_files = [
            'backend_worker/celery_app.py',
            'backend_worker/background_tasks/optimized_scan.py',
            'backend_worker/background_tasks/optimized_extract.py',
            'backend_worker/background_tasks/optimized_batch.py',
            'backend_worker/background_tasks/optimized_insert.py',
            'docker-compose-scan-optimized.yml',
            'tests/test_optimized_scan_integration.py',  # Tests d'intÃ©gration
            'tests/backend/test_optimized_scan.py',
            'tests/backend/test_celery_optimization.py',
            'tests/benchmark/benchmark_optimized_scan.py'
        ]

        for file_path in required_files:
            if os.path.exists(file_path):
                self.log(f"  âœ“ {file_path}")
            else:
                self.log(f"  âœ— {file_path} manquant", "ERROR")
                return False

        self.log("âœ“ Structure des fichiers OK")
        return True

    def run_pytest_tests(self):
        """ExÃ©cute les tests pytest crÃ©Ã©s."""
        self.log("ExÃ©cution des tests pytest...")

        success, output = self.run_command(
            "python -m pytest tests/backend/test_optimized_scan.py -v",
            "Tests des fonctionnalitÃ©s optimisÃ©es",
            timeout=120
        )

        if success:
            self.log("âœ“ Tests pytest rÃ©ussis")
            return True
        else:
            self.log(f"âœ— Ã‰chec tests pytest: {output}", "ERROR")
            return False

    def run_benchmark(self):
        """ExÃ©cute le benchmark de performance."""
        self.log("ExÃ©cution du benchmark...")

        success, output = self.run_command(
            "python tests/benchmark/benchmark_optimized_scan.py",
            "Benchmark de performance",
            timeout=300  # 5 minutes pour le benchmark
        )

        if success:
            self.log("âœ“ Benchmark rÃ©ussi")
            return True
        else:
            self.log(f"âœ— Ã‰chec benchmark: {output}", "ERROR")
            return False

    async def run_async_tests(self):
        """ExÃ©cute les tests asynchrones."""
        self.log("Tests asynchrones...")

        try:
            # Test d'import des modules asynchrones
            from backend_worker.background_tasks.optimized_scan import scan_directory_parallel

            self.log("âœ“ Imports asynchrones OK")

            # Test simple d'exÃ©cution (sans fichiers rÃ©els)
            import tempfile
            with tempfile.TemporaryDirectory() as temp_dir:
                # CrÃ©er un petit rÃ©pertoire de test
                test_dir = Path(temp_dir) / "test_music"
                test_dir.mkdir()

                file_path = test_dir / "test.mp3"
                file_path.write_text("test content")

                # Test de scan avec mock
                import unittest.mock
                with unittest.mock.patch('backend_worker.background_tasks.optimized_scan.celery') as mock_celery:
                    mock_task = unittest.mock.MagicMock()
                    mock_celery.send_task.return_value = mock_task

                    result = await scan_directory_parallel(str(test_dir), batch_size=10)

                    if result['success']:
                        self.log("âœ“ Test scan asynchrone OK")
                        return True
                    else:
                        self.log(f"âœ— Ã‰chec test scan asynchrone: {result}", "ERROR")
                        return False

        except Exception as e:
            self.log(f"âœ— Erreur tests asynchrones: {e}", "ERROR")
            return False

    def generate_deployment_report(self):
        """GÃ©nÃ¨re un rapport de dÃ©ploiement."""
        self.log("GÃ©nÃ©ration rapport de dÃ©ploiement...")

        report = {
            'timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
            'test_results': len(self.results),
            'errors': len(self.errors),
            'summary': 'OK' if not self.errors else 'ERREURS',
            'details': {
                'results': self.results,
                'errors': self.errors
            }
        }

        # Sauvegarder le rapport
        report_file = f"deployment_test_report_{int(time.time())}.json"
        with open(report_file, 'w') as f:
            import json
            json.dump(report, f, indent=2)

        self.log(f"Rapport sauvegardÃ©: {report_file}")

        return report

    async def run_all_tests(self):
        """ExÃ©cute tous les tests de dÃ©ploiement."""
        self.log("ğŸš€ DÃ‰MARRAGE TESTS DE DÃ‰PLOIEMENT")
        self.log("=" * 50)

        tests = [
            ('Environnement Python', self.test_python_environment),
            ('Configuration Celery', self.test_celery_configuration),
            ('TÃ¢ches optimisÃ©es', self.test_optimized_tasks),
            ('Connexion base de donnÃ©es', self.test_database_connection),
            ('Connexion Redis', self.test_redis_connection),
            ('Configuration Docker Compose', self.test_docker_compose),
            ('Structure des fichiers', self.test_file_structure),
            ('Tests pytest', self.run_pytest_tests),
            ('Tests asynchrones', self.run_async_tests),
            ('Benchmark performance', self.run_benchmark),
        ]

        for test_name, test_func in tests:
            self.log(f"\nğŸ“‹ TEST: {test_name}")
            self.log("-" * 30)

            try:
                if asyncio.iscoroutinefunction(test_func):
                    result = await test_func()
                else:
                    result = test_func()

                if result:
                    self.results.append(test_name)
                    self.log(f"âœ“ {test_name} RÃ‰USSI")
                else:
                    self.log(f"âœ— {test_name} Ã‰CHEC")

            except Exception as e:
                self.log(f"ğŸ’¥ Exception dans {test_name}: {e}", "ERROR")

        # Rapport final
        self.log("\n" + "=" * 50)
        self.log("RAPPORT FINAL DE DÃ‰PLOIEMENT")
        self.log("=" * 50)

        self.log(f"Tests rÃ©ussis: {len(self.results)}/{len(tests)}")
        self.log(f"Erreurs: {len(self.errors)}")

        if self.errors:
            self.log("âŒ ERREURS DÃ‰TECTÃ‰ES:")
            for error in self.errors:
                self.log(f"  â€¢ {error}")

        if len(self.results) >= len(tests) * 0.8:  # Au moins 80% de succÃ¨s
            self.log("ğŸ‰ DÃ‰PLOIEMENT PRÃŠT!")
            self.log("\nğŸ“‹ Prochaines Ã©tapes:")
            self.log("1. DÃ©marrer les workers: docker-compose -f docker-compose-scan-optimized.yml up -d")
            self.log("2. Tester avec un petit rÃ©pertoire")
            self.log("3. Surveiller les performances")
            self.log("4. DÃ©ployer en production")

            self.generate_deployment_report()
            return True
        else:
            self.log("ğŸ’¥ TROP D'ERREURS - DÃ‰PLOIEMENT NON RECOMMANDÃ‰")
            self.log("Corriger les erreurs avant dÃ©ploiement")

            self.generate_deployment_report()
            return False


async def main():
    """Fonction principale."""
    print("ğŸš€ TEST DE DÃ‰PLOIEMENT - SYSTÃˆME DE SCAN OPTIMISÃ‰")
    print("=" * 60)

    test = DeploymentTest()
    success = await test.run_all_tests()

    print(f"\nğŸ RÃ‰SULTAT: {'SUCCÃˆS' if success else 'Ã‰CHEC'}")

    return success


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)