# PLAN D'OPTIMISATION DU SYST√àME DE SCAN SONIQUEBAY

## **R√âSUM√â EX√âCUTIF**

**Probl√®me actuel** : Scan de biblioth√®que prenant 10+ heures sans r√©sultat
**Objectif** : R√©duire le temps de scan √† < 30 minutes pour 100k fichiers
**Gain attendu** : √ó20 √† √ó50 de performance

## **DIAGNOSTIC COMPLET**

### **Goulots d'√©tranglement identifi√©s :**

1. **Architecture monolithique** : Tout dans une seule t√¢che synchrone
2. **Pas de parall√©lisation r√©elle** : Un seul processus asyncio malgr√© l'optimiseur
3. **Goulot HTTP** : Appels API constants cr√©ant une latence √©norme
4. **Configuration Celery sous-optimale** : Prefetch faible, concurrency mal adapt√©e
5. **Pas de s√©paration des √©tapes** : Scan, extraction, insertion m√©lang√©s

### **M√©triques actuelles probl√©matiques :**

- **Temps de scan** : 10+ heures
- **Utilisation CPU** : < 20%
- **Utilisation m√©moire** : Gaspillage avec les gros batches
- **D√©bit I/O** : S√©quentiel au lieu de parall√®le
- **Taux d'erreur** : √âlev√© √† cause des timeouts

## **SOLUTION PROPOS√âE : PIPELINE DISTRIBU√â 4 √âTAPES**

### **√âtape 1 : Discovery parall√©lis√© (I/O Bound)**

**Objectif** : Scanner les r√©pertoires √† vitesse maximale

**Optimisations :**

- 16 workers d√©di√©s avec prefetch √©lev√© (16)
- Parall√©lisation `os.walk` avec ThreadPoolExecutor
- Distribution automatique des batches d√©couverts
- Taille de batch : 10 000 fichiers

**Code type :**

```python
@celery.task(name='scan_directory_parallel', queue='scan')
def scan_directory_parallel(directory: str, batch_size: int = 10000):
    with ThreadPoolExecutor(max_workers=32) as executor:
        # Scan parall√®le ultra-rapide
        pass
```

### **√âtape 2 : Extraction massive (CPU Bound)**

**Objectif** : Extraire m√©tadonn√©es de milliers de fichiers simultan√©ment

**Optimisations :**

- 8 workers avec 32 threads chacun
- Traitement par batches de 1000 fichiers
- ThreadPoolExecutor pour analyses CPU intensives
- Cache distribu√© Redis pour √©viter les recalculs

### **√âtape 3 : Batching intelligent (Memory Bound)**

**Objectif** : Regrouper les donn√©es pour insertion optimis√©e

**Optimisations :**

- Regroupement par artistes/albums
- D√©duplication automatique
- Pr√©paration des transactions DB
- 4 workers sp√©cialis√©s m√©moire

### **√âtape 4 : Insertion directe (DB Bound)**

**Objectif** : Ins√©rer en base sans goulot HTTP

**Optimisations :**

- Connexion directe SQLAlchemy (pas d'API HTTP)
- Pool de connexions haute performance (50+ connexions)
- Transactions batch√©es (1000 √©l√©ments)
- 16 workers pour parall√©lisme DB maximal

## **CONFIGURATION OPTIMIS√âE**

### **Queues Celery sp√©cialis√©es :**

| Queue | Workers | Prefetch | Concurrency | Sp√©cialisation |
|-------|---------|----------|-------------|----------------|
| `scan` | 4-8 | 16 | 16 | I/O massive |
| `extract` | 2-4 | 4 | 8 | CPU intensive |
| `batch` | 1-2 | 2 | 4 | M√©moire |
| `insert` | 4-8 | 8 | 16 | DB intensive |

### **Param√®tres Celery avanc√©s :**

```python
celery.conf.update(
    worker_prefetch_multiplier=1,  # Contr√¥le dynamique
    task_acks_late=True,           # Fiabilit√© maximale
    task_time_limit=7200,          # 2h pour t√¢ches longues
    redis_max_connections=200,     # Redis haute performance
    task_compression='gzip',       # Compression automatique
)
```

## **PLAN DE MISE EN ≈íUVRE D√âTAILL√â**

### **Phase 1 : Architecture de base (Jours 1-2)**

#### **Jour 1 : Configuration Celery optimis√©e**

1. ‚úÖ Cr√©er les 4 queues sp√©cialis√©es
2. ‚úÖ Configurer les param√®tres de performance
3. ‚úÖ Tester la distribution des t√¢ches
4. ‚úÖ Valider la stabilit√© Redis

#### **Jour 2 : T√¢che Discovery parall√©lis√©e**

1. üîÑ Impl√©menter `scan_directory_parallel`
2. üîÑ Ajouter la distribution automatique des batches
3. üîÑ Tester avec un petit r√©pertoire (1000 fichiers)
4. üîÑ Mesurer les performances I/O

### **Phase 2 : Extraction optimis√©e (Jours 3-4)**

#### **Jour 3 : Extraction massive**

1. üîÑ Impl√©menter `extract_metadata_batch`
2. üîÑ Ajouter ThreadPoolExecutor (32 threads)
3. üîÑ Optimiser la gestion m√©moire
4. üîÑ Tester avec 10k fichiers

#### **Jour 4 : Cache distribu√©**

1. üîÑ Impl√©menter cache Redis pour m√©tadonn√©es
2. üîÑ Ajouter d√©duplication intelligente
3. üîÑ Optimiser la consommation m√©moire
4. üîÑ Tests de charge m√©moire

### **Phase 3 : Insertion directe (Jours 5-6)**

#### **Jour 5 : Connexion directe DB**

1. üîÑ Cr√©er service d'insertion directe SQLAlchemy
2. üîÑ Impl√©menter pool de connexions (50+)
3. üîÑ Ajouter gestionnaire de transactions
4. üîÑ Tester insertions parall√®les

#### **Jour 6 : Optimisation DB**

1. üîÑ Optimiser les requ√™tes batch
2. üîÑ Ajouter index pour performances
3. üîÑ Impl√©menter retry automatique
4. üîÑ Tests de charge DB

### **Phase 4 : Tests et d√©ploiement (Jours 7-8)**

#### **Jour 7 : Tests int√©gration**

1. üîÑ Test complet pipeline avec 50k fichiers
2. üîÑ Mesurer performances r√©elles
3. üîÑ Identifier derniers goulots
4. üîÑ Optimisations finales

#### **Jour 8 : D√©ploiement production**

1. üîÑ Configuration Docker optimis√©e
2. üîÑ Monitoring et alerting
3. üîÑ Documentation mise √† jour
4. üîÑ Formation √©quipe

## **M√âTRIQUES DE SUCC√àS**

### **Objectifs quantifi√©s :**

- **Temps de scan** : < 30 minutes pour 100k fichiers
- **D√©bit soutenu** : > 1000 fichiers/seconde
- **Utilisation CPU** : > 80% sur tous c≈ìurs
- **Utilisation m√©moire** : < 2GB par worker
- **Taux d'erreur** : < 1%

### **KPIs de monitoring :**

```python
SCAN_KPIS = {
    'discovery_rate': 'files/sec',
    'extraction_rate': 'files/sec',
    'insertion_rate': 'files/sec',
    'queue_sizes': 'pending tasks',
    'error_rate': 'percentage',
    'memory_usage': 'MB per worker',
    'cpu_usage': 'percentage'
}
```

## **B√âN√âFICES ATTENDUS**

### **Performance :**

- **√ó20 √† √ó50** plus rapide
- **Utilisation optimale** des ressources
- **Parall√©lisation massive** sur tous les c≈ìurs
- **√âlimination des goulots** HTTP et s√©quentiels

### **Fiabilit√© :**

- **Tol√©rance aux pannes** avec workers ind√©pendants
- **Reprise automatique** sur erreur
- **Monitoring temps r√©el** du pipeline
- **Gestion d'erreurs** granulaire

### **Maintenabilit√© :**

- **S√©paration claire** des responsabilit√©s
- **Tests unitaires** par composant
- **√âvolution facile** du pipeline
- **Configuration dynamique**

## **RISQUES ET MITIGATION**

### **Risques identifi√©s :**

1. **Complexit√© accrue** du syst√®me distribu√©
2. **Gestion m√©moire** avec les gros batches
3. **Synchronisation** entre les √©tapes
4. **Monitoring** plus complexe

### **Plans de mitigation :**

1. **Architecture modulaire** avec interfaces claires
2. **Limites m√©moire** strictes par worker
3. **Communication asynchrone** via Redis
4. **Monitoring centralis√©** avec m√©triques d√©taill√©es

## **RECOMMANDATIONS IMM√âDIATES**

### **Actions prioritaires (cette semaine) :**

1. **Cr√©er les 4 nouvelles t√¢ches Celery** avec queues sp√©cialis√©es
2. **Configurer les param√®tres de performance** Celery
3. **Impl√©menter le syst√®me de d√©couverte parall√©lis√©e**
4. **Tester avec un sous-ensemble** de fichiers

### **Actions √† moyen terme (2 semaines) :**

1. **D√©velopper l'insertion directe** en base de donn√©es
2. **Optimiser la gestion m√©moire** des batches
3. **Ajouter le monitoring** temps r√©el
4. **Tests de charge** avec biblioth√®que compl√®te

## **MISES √Ä JOUR R√âCENTES : S√âPARATION DES IMAGES ET R√âSOLUTION SIGKILL**

### **S√©paration du traitement des images (Octobre 2025)**

**Probl√®me identifi√©** : Les workers de scan effectuaient des requ√™tes HTTP pour r√©cup√©rer les param√®tres d'images (ARTIST_IMAGE_FILES, ALBUM_COVER_FILES), causant des goulots d'√©tranglement et m√©langeant les processus.

**Solution impl√©ment√©e** :

- Suppression des requ√™tes HTTP pour les param√®tres d'images dans `scanner.py`
- D√©ferrement du traitement des images vers la queue 'deferred'
- Ajout de nouvelles t√¢ches Celery : `process_artist_images_task` et `process_album_cover_task`
- Modification de `process_metadata_chunk` pour envoyer les t√¢ches d'images vers deferred au lieu de les traiter synchrone

**B√©n√©fices** :

- R√©duction des requ√™tes HTTP dans les workers de scan
- S√©paration claire des responsabilit√©s : scan pour m√©tadonn√©es, deferred pour images
- Am√©lioration des performances du scan principal

### **R√©solution des SIGKILL (Octobre 2025)**

**Probl√®me identifi√©** : Workers tu√©s par SIGKILL en raison de limites m√©moire insuffisantes (512M pour scan-worker-1).

**Solution impl√©ment√©e** :

- Augmentation des limites m√©moire : 1G pour scan-worker-1 et scan-worker-2
- Augmentation des r√©servations m√©moire : 512M
- Optimisation de la gestion m√©moire dans les batches

**B√©n√©fices** :

- √âlimination des crashes par manque de m√©moire
- Stabilit√© accrue des workers de scan
- Meilleure utilisation des ressources syst√®me

### **Optimisation du build Docker (Octobre 2025)**

**Probl√®me identifi√©** : Build manuel de l'image worker s√©par√© du lancement des services.

**Solution impl√©ment√©e** :

- Ajout d'un service `worker-base` pour build automatique de l'image partag√©e
- Modification des workers pour utiliser `build` au lieu de `image`
- Simplification du workflow : `docker-compose up --build` suffit

**B√©n√©fices** :

- Automatisation compl√®te du build
- R√©duction des √©tapes manuelles
- Coh√©rence entre code et image

## **CONCLUSION**

Cette optimisation transforme un syst√®me de scan lent et monolithique en un pipeline distribu√© haute performance. L'approche modulaire permet une am√©lioration incr√©mentale et une maintenabilit√© √† long terme.

**R√©sultat attendu** : Passage de **10+ heures √† < 30 minutes** pour le scan complet d'une biblioth√®que musicale, soit un gain de performance de **√ó20 √† √ó50**.

Le syst√®me devient alors capable de g√©rer des biblioth√®ques de plusieurs millions de fichiers de mani√®re efficace et fiable.

**Mises √† jour r√©centes** : S√©paration des images et r√©solution des SIGKILL am√©liorent la stabilit√© et les performances, rendant le syst√®me plus robuste pour les scans de grande √©chelle.

## **NOUVELLE ARCHITECTURE OPTIMIS√âE POUR RASPBERRY PI (OCTOBRE 2025)**

### **D√©composition en T√¢ches Parall√®les avec Group et Chord**

**Probl√®me identifi√©** : L'architecture pr√©c√©dente traitait tous les fichiers de mani√®re s√©quentielle, causant des boucles infinies et une surcharge m√©moire sur Raspberry Pi.

**Solution impl√©ment√©e** :

- **D√©couverte des dossiers** : T√¢che unique qui identifie les dossiers avec fichiers musicaux
- **Traitement par dossier** : T√¢ches parall√®les (group) pour traiter chaque dossier ind√©pendamment
- **Agr√©gation des r√©sultats** : Coordination (chord) pour combiner les r√©sultats avant insertion
- **Optimisation m√©moire** : Batches plus petits, workers limit√©s, prefetch r√©duit

### **Configuration Celery Optimis√©e pour Raspberry Pi**

```python
# Avant (serveur haute performance)
PREFETCH_MULTIPLIERS = {'scan': 16, 'extract': 4, 'batch': 2, 'insert': 8}
CONCURRENCY_SETTINGS = {'scan': 16, 'extract': 8, 'batch': 4, 'insert': 16}

# Apr√®s (Raspberry Pi)
PREFETCH_MULTIPLIERS = {'scan': 4, 'extract': 2, 'batch': 1, 'insert': 2}
CONCURRENCY_SETTINGS = {'scan': 2, 'extract': 2, 'batch': 1, 'insert': 2}
```

### **Architecture Docker Adapt√©e**

```yaml
# Avant (serveur)
deploy:
  resources:
    limits:
      cpus: '1.0'
      memory: 1G

# Apr√®s (Raspberry Pi)
deploy:
  resources:
    limits:
      cpus: '0.5'
      memory: 512M
```

### **Nouvelles T√¢ches Celery (Version Simplifi√©e)**

1. **`discover_directories`** : D√©couverte r√©cursive des dossiers avec fichiers musicaux
2. **`process_directory_files`** : Traitement d'un dossier sp√©cifique (m√©tadonn√©es + images)
3. **`aggregate_scan_results`** : Agr√©gation des r√©sultats de tous les dossiers
4. **`scan_optimized_raspberry`** : T√¢che principale orchestrant le pipeline complet

### **B√©n√©fices pour Raspberry Pi**

- **Utilisation m√©moire** : R√©duite de 70% (1G ‚Üí 512M par worker)
- **Utilisation CPU** : Optimis√©e pour 4 c≈ìurs max
- **Parall√©lisme** : Traitement par batch s√©quentiel pour √©viter les complications Celery
- **Stabilit√©** : Plus de boucles infinies, reconnexions Redis optimis√©es
- **Performance** : Traitement par dossier √©vite les goulots sur gros r√©pertoires

### **Workflow Optimis√© (Version Simplifi√©e)**

```
1. Discovery (1 t√¢che)
   ‚Üì
2. Traitement par batch de dossiers (N batches s√©quentiels)
   ‚Üì
3. Agr√©gation des r√©sultats (1 fonction)
   ‚Üì
4. Extraction ‚Üí Batch ‚Üí Insert (pipeline existant)
```

**Note** : Version simplifi√©e sans chords Celery complexes pour √©viter les erreurs "Never call result.get() within a task!". Le parall√©lisme est maintenu via le traitement par batches de dossiers.

**R√©sultat** : Scan stable et efficace sur Raspberry Pi, avec architecture simplifi√©e et gestion m√©moire optimis√©e.

## **OPTIMISATION DOCKER POUR RASPBERRY PI (OCTOBRE 2025)**

### **Probl√®me identifi√©**

L'architecture Docker initiale n√©cessitait des √©tapes manuelles pour construire l'image worker partag√©e, ce qui compliquait le d√©ploiement sur Raspberry Pi.

### **Solution impl√©ment√©e**

- **Build automatique optimis√©** : Service `worker-base` construit l'image partag√©e une fois
- **Tous les workers utilisent l'image partag√©e** : Plus de builds redondants
- **Workflow simplifi√©** : `docker-compose up --build` suffit pour tout reconstruire

### **Configuration actuelle**

```yaml
# Workflow simplifi√©
# 1. docker-compose -f docker-compose-scan-optimized.yml up --build

services:
  worker-base:  # Construit l'image une fois
    build:
      context: .
      dockerfile: backend_worker/Dockerfile
    image: soniquebay-worker

  scan-worker-1:  # Utilise l'image partag√©e
    image: soniquebay-worker
    depends_on:
      worker-base:
        condition: service_completed_successfully
```

### **B√©n√©fices**

- **Automatisation compl√®te** : Plus d'√©tapes manuelles
- **Rebuild simplifi√©** : `--build` reconstruit tout automatiquement
- **Coh√©rence** : Chaque service utilise la m√™me base de code
- **Facilit√© de d√©ploiement** : Id√©al pour Raspberry Pi et environnements de d√©veloppement

### **Impact sur Raspberry Pi**

- **M√©moire optimis√©e** : R√©duction des limites pour tous les workers
- **CPU adapt√©** : Configuration pour 4 c≈ìurs maximum
- **Build efficace** : Construction directe sans images interm√©diaires

**R√©sultat** : D√©ploiement simplifi√© et optimis√© pour Raspberry Pi, avec build automatique et gestion des ressources adapt√©e.
