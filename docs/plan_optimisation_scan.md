# Plan d'optimisation du scan et int√©gration DB - SoniqueBay

**Date de cr√©ation** : 20 septembre 2025
**Auteur** : Kilo Code (Architect Mode)
**Objectif** : Optimiser les vitesses de scan et d'int√©gration dans la base de donn√©es, utiliser GraphQL pour les batch, corriger les probl√®mes identifi√©s.

---

## Probl√®mes identifi√©s lors de l'analyse

1. **Relation manquante Track-TrackVector** : Le mod√®le `Track` n'a pas de relation avec `TrackVector`, emp√™chant le stockage des vecteurs
2. **Vecteurs jamais calcul√©s** : Aucune t√¢che Celery pour g√©n√©rer les embeddings vectoriels des tracks
3. **Analyse audio incompl√®te** : Les champs d'analyse audio existent mais ne sont pas remplis correctement lors du scan
4. **Covers d'artistes probl√©matiques** : Gestion des covers d'artistes d√©faillante dans `entity_manager.py`
5. **Utilisation de REST au lieu de GraphQL** : Le scanner utilise encore les endpoints REST `/batch` au lieu des mutations GraphQL optimis√©es
6. **Documentation manquante** : Classes et fonctions sans docstrings selon les r√®gles AGENTS.md

---

## Architecture propos√©e

```mermaid
graph TD
    A[Scan d√©clench√©] --> B[Scanner Worker]
    B --> C[Parall√©lisation par chunks]
    C --> D[Extraction m√©tadonn√©es]
    D --> E[Mutations GraphQL batch]
    E --> F[Analyse audio parall√®le]
    F --> G[Calcul vecteurs]
    G --> H[Indexation Whoosh]

    subgraph "Optimisations"
        I[Chunks de 500+ √©l√©ments]
        J[Async/await partout]
        K[Cache Redis pour m√©tadonn√©es]
        L[Index DB optimis√©s]
    end

    subgraph "GraphQL Mutations"
        M[create_artists_batch]
        N[create_albums_batch]
        O[create_tracks_batch]
    end
```

---

## Plan d'optimisation d√©taill√©

### ‚úÖ T√¢ches termin√©es
- [x] Analyser le code existant et identifier les probl√®mes (covers artistes, analyse audio, vecteurs)
- [x] **Parall√©lisation des chunks DB** : Impl√©menter le traitement parall√®le des chunks avec `asyncio.gather`
- [x] **Augmentation de la concurrence** : max_concurrent_files=200, max_concurrent_audio=40, max_parallel_chunks=4
- [x] **Optimisation des tailles de batch** : file_batch=500, chunk_size=200 pour maximiser le d√©bit
- [x] **Benchmarks de performance** : Cr√©er `benchmark_scanner_performance.py` pour mesurer les am√©liorations
- [x] **Tests unitaires** : Ajouter tests pour la parall√©lisation dans `test_scanner.py`

### üîÑ En cours
- [ ] Corriger la relation manquante entre Track et TrackVector dans le mod√®le

### üìã T√¢ches √† r√©aliser

1. **Impl√©menter la t√¢che de calcul des vecteurs pour les tracks**
   - Cr√©er une nouvelle t√¢che Celery `vectorize_tracks_task`
   - Int√©grer un mod√®le d'embedding (Ollama ou autre)
   - Stocker les vecteurs dans `track_vectors` table
   - G√©rer les erreurs et retries

2. **Optimiser l'analyse audio avec parall√©lisation et gestion d'erreurs am√©lior√©e**
   - Augmenter la parall√©lisation des analyses Librosa
   - Am√©liorer la gestion des √©checs avec retry intelligent
   - Optimiser l'extraction des features AcoustID
   - Cache des r√©sultats d'analyse

3. **Corriger la gestion des covers d'artistes dans entity_manager.py**
   - D√©boguer la logique de traitement des covers artistes
   - V√©rifier les chemins et URLs des images
   - Am√©liorer la gestion d'erreurs pour les covers

4. **Remplacer les appels REST par GraphQL dans le scanner pour les op√©rations batch**
   - Migrer `create_or_get_artists_batch` vers `create_artists` GraphQL
   - Migrer `create_or_get_albums_batch` vers `create_albums` GraphQL
   - Migrer `create_or_update_tracks_batch` vers `create_tracks` GraphQL
   - Utiliser httpx pour les requ√™tes GraphQL

5. **Augmenter la taille des chunks pour am√©liorer les performances de batch**
   - Passer de 200 √† 500+ √©l√©ments par chunk
   - Ajuster les timeouts en cons√©quence
   - Monitorer l'impact m√©moire

6. **Ajouter des docstrings compl√®tes √† toutes les classes et fonctions selon AGENTS.md**
   - Documenter tous les services (TrackService, ScanService, etc.)
   - Documenter les t√¢ches Celery
   - Documenter les utilitaires et helpers
   - Respecter le format PEP8 et r√®gles de l'√©quipe

7. **Impl√©menter des index DB pour optimiser les requ√™tes de scan**
   - Index sur `tracks.path` pour les lookups rapides
   - Index composite sur `(artist_id, album_id)` pour les relations
   - Index sur `musicbrainz_id` pour les d√©duplications
   - Analyser les queries lentes avec EXPLAIN

8. **Ajouter des m√©triques de performance et monitoring pour le scan**
   - M√©triques Prometheus pour dur√©e des t√¢ches
   - Compteurs d'erreurs et succ√®s
   - Monitoring de la queue Celery
   - Dashboards Grafana pour visualisation

9. **Cr√©er des tests d'int√©gration pour valider les corrections**
   - Test complet scan ‚Üí analyse ‚Üí vectorisation
   - Tests de performance avec gros volumes
   - Tests de r√©silience (erreurs r√©seau, DB down)
   - Validation des donn√©es en base

10. **Documenter les nouveaux endpoints et workflows**
    - Mettre √† jour la documentation API
    - Documenter les workflows asynchrones
    - Cr√©er des guides pour les d√©veloppeurs
    - Mettre √† jour les README

---

## Optimisations impl√©ment√©es - Session 4 octobre 2025

### üöÄ Parall√©lisation des chunks DB
- **Avant** : Chunks trait√©s s√©quentiellement un par un
- **Apr√®s** : Traitement parall√®le de 4 chunks simultan√©ment avec `asyncio.gather`
- **Impact** : R√©duction significative du temps d'insertion DB pour gros volumes

### ‚ö° Augmentation de la concurrence
- **max_concurrent_files** : 50 ‚Üí 200 (+300%)
- **max_concurrent_audio** : 10 ‚Üí 40 (+300%)
- **max_parallel_chunks** : 1 ‚Üí 4 (nouveau param√®tre)
- **Impact** : Meilleure utilisation des ressources CPU/m√©moire

### üì¶ Optimisation des tailles de batch
- **file_batch** : 200 ‚Üí 500 (+150%) pour extraction
- **chunk_size** : 500 ‚Üí 200 (-60%) pour parall√©lisation
- **Impact** : √âquilibre entre latence r√©seau et parall√©lisation

### üß™ Benchmarks et tests
- **Nouveau benchmark** : `tests/benchmark/benchmark_scanner_performance.py`
- **Tests unitaires** : Validation parall√©lisation dans `test_scanner.py`
- **Configurations test√©es** : baseline, optimized, high_concurrency

### üìä Projections de performance
- **30 000 tracks** : Objectif < 10 minutes (comme autres outils)
- **Throughput cible** : 50-100 fichiers/seconde
- **Utilisation ressources** : Optimis√©e pour Raspberry Pi 4

## M√©triques cibles d'optimisation

- **Temps de scan** : R√©duction de 50-70% gr√¢ce √† la parall√©lisation compl√®te
- **Utilisation m√©moire** : Stable malgr√© chunks plus gros
- **Taux d'erreur** : < 5% pour les analyses audio
- **Couverture donn√©es** : 100% des champs d'analyse remplis
- **Performance DB** : Queries < 100ms en moyenne

---

## Risques et mitigation

- **Migration GraphQL** : Tests approfondis avant d√©ploiement
- **Performance chunks** : Monitoring m√©moire et rollback possible
- **Compatibilit√©** : Tests de r√©gression complets
- **D√©pendances externes** : Circuit breaker pour APIs tierces

---

## Sessions de travail planifi√©es

Cette liste de t√¢ches sera mise √† jour au fur et √† mesure des sessions de travail. Chaque t√¢che sera marqu√©e comme :
- ‚úÖ Termin√©e
- üîÑ En cours
- üìã √Ä faire
- ‚ùå Bloqu√©e (avec raison)

**Prochaine session** : Correction relation Track-TrackVector et impl√©mentation calcul vecteurs.